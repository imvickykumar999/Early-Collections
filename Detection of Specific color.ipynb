{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of a specific color (blue here)\n",
    "\n",
    "## https://www.pyimagesearch.com/2014/08/04/opencv-python-color-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# Webcamera no 0 is used to capture the frames \n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# This drives the program into an infinite loop. \n",
    "while(1):\t \n",
    "    \n",
    "    # Captures the live stream frame-by-frame \n",
    "    _, frame = cap.read() \n",
    "    \n",
    "    # Converts images from BGR to HSV \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    \n",
    "    lower_red = np.array([110,50,50]) \n",
    "    upper_red = np.array([130,255,255]) \n",
    "\n",
    "    # Here we are defining range of bluecolor in HSV \n",
    "    # This creates a mask of blue coloured \n",
    "    # objects found in the frame. \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red) \n",
    "\n",
    "    # The bitwise and of the frame and mask is done so \n",
    "    # that only the blue coloured objects are highlighted \n",
    "    # and stored in res \n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('hsv',hsv)\n",
    "    cv2.imshow('mask',mask) \n",
    "    cv2.imshow('res',res) \n",
    "\n",
    "    # This displays the frame, mask \n",
    "    # and res which we created in 3 separate windows. \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27: # 27 means ESC button \n",
    "        break\n",
    "\n",
    "# Destroys all of the HighGUI windows. \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "# release the captured frame \n",
    "cap.release() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designers use the HSV color model when selecting colors for paint or ink because HSV better represents how people relate to colors than the RGB color model does.\n",
    "# HSV FULL FORM...\n",
    "# HUE\n",
    "## Hue is the color portion of the model, expressed as a number from 0 to 360 degrees:\n",
    "\n",
    "## Red falls between 0 and 60 degrees.\n",
    "## Yellow falls between 61 and 120 degrees.\n",
    "## Green falls between 121-180 degrees.\n",
    "## Cyan falls between 181-240 degrees.\n",
    "## Blue falls between 241-300 degrees.\n",
    "## Magenta falls between 301-360 degrees.\n",
    "## SATURATION\n",
    "## Saturation describes the amount of gray in a particular color, from 0 to 100 percent. Reducing this component toward zero introduces more gray and produces a faded effect. Sometimes, saturation appears as a range from just 0-1, where 0 is gray, and 1 is a primary color.\n",
    "\n",
    "# VALUE (OR BRIGHTNESS)\n",
    "## Value works in conjunction with saturation and describes the brightness or intensity of the color, from 0-100 percent, where 0 is completely black, and 100 is the brightest and reveals the most color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "## Learning Step by Step EXECUTION of Shell.... ✌✌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<VideoCapture 0000022A02279DD0>, cv2.VideoCapture, type)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# Webcamera no 0 is used to capture the frames \n",
    "cap = cv2.VideoCapture(0) \n",
    "cap, cv2.VideoCapture, type(cv2.VideoCapture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drives the program into an infinite loop. \n",
    "# while(1):\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " <function VideoCapture.read>,\n",
       " builtin_function_or_method,\n",
       " numpy.ndarray,\n",
       " bool)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Captures the live stream frame-by-frame \n",
    "_, frame = cap.read() \n",
    "_, frame, cap.read, type(cap.read), type(frame), type(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " numpy.ndarray,\n",
       " <function cvtColor>,\n",
       " builtin_function_or_method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts images from BGR to HSV \n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "hsv, type(hsv), cv2.cvtColor, type(cv2.cvtColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([110,  50,  50]),\n",
       " array([130, 255, 255]),\n",
       " <function numpy.array>,\n",
       " builtin_function_or_method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_red = np.array([110,50,50])\n",
    "upper_red = np.array([130,255,255])\n",
    "\n",
    "lower_red, upper_red, np.array, type(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " <function inRange>,\n",
       " builtin_function_or_method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are defining range of bluecolor in HSV \n",
    "# This creates a mask of blue coloured \n",
    "# objects found in the frame.\n",
    "\n",
    "mask = cv2.inRange(hsv, lower_red, upper_red) \n",
    "mask, cv2.inRange, type(cv2.inRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " <function bitwise_and>,\n",
       " builtin_function_or_method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The bitwise and of the frame and mask is done so \n",
    "# that only the blue coloured objects are highlighted \n",
    "# and stored in res\n",
    "\n",
    "res = cv2.bitwise_and(frame,frame, mask= mask) \n",
    "res, cv2.bitwise_and, type(cv2.bitwise_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('frame',frame)\n",
    "# cv2.imshow('hsv',hsv)\n",
    "# cv2.imshow('mask',mask) \n",
    "# cv2.imshow('res',res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # This displays the frame, mask \n",
    "#     # and res which we created in 3 separate windows. \n",
    "#     k = cv2.waitKey(5) & 0xFF\n",
    "#     if k == 27: # 27 means ESC button \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroys all of the HighGUI windows. \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# release the captured frame \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# #  Log system        \n",
    "# class PS_Search_Color:\n",
    "    \n",
    "# #     frame\n",
    "    \n",
    "#     def __init__(self, frame):\n",
    "#         self.frame = frame\n",
    "    \n",
    "#     def color_detection(self, frame_in):\n",
    "#         # Take each frame\n",
    "#         #frame = cv2.imread(image_name)\n",
    "#         src_height, src_width, src_channels = frame_in.shape\n",
    "#         roiX = int(src_width / 4)\n",
    "#         roiWidth = roiX * 2\n",
    "#         roiY = src_height / 4\n",
    "#         roiHeight = roiY * 2\n",
    "# #         frame = frame_in[roiY : roiY+roiHeight, roiX : roiX+roiWidth]\n",
    "\n",
    "#         src_height, src_width, src_channels = frame.shape\n",
    "#         max_value = src_height * src_width * 255\n",
    "\n",
    "#         # Convert BGR to HSV\n",
    "#         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#         # detect red\n",
    "#         lower = np.array([150, 30, 30])\n",
    "#         upper = np.array([190, 255, 255])\n",
    "#         mask1 = cv2.inRange(hsv, lower, upper)\n",
    "#         lower = np.array([0, 30, 30])\n",
    "#         upper = np.array([10, 255, 255])\n",
    "#         mask2 = cv2.inRange(hsv, lower, upper)\n",
    "#         mask = mask1 + mask2\n",
    "#         redVal = float(mask.sum()) / float(max_value)\n",
    "#         if redVal > 0.2:\n",
    "#             red=\"true\"\n",
    "#         else:\n",
    "#             red=\"false\"\n",
    "\n",
    "#         # detect yellow\n",
    "#         lower = np.array([5, 100, 100])\n",
    "#         upper = np.array([40, 255, 255])\n",
    "#         mask = cv2.inRange(hsv, lower, upper)\n",
    "#         yellowVal = float(mask.sum()) / float(max_value)\n",
    "#         if yellowVal > 0.15:\n",
    "#             yellow=\"true\"\n",
    "#         else:\n",
    "#             yellow=\"false\"\n",
    "\n",
    "#         # detect blue\n",
    "#         lower = np.array([100, 60, 60])\n",
    "#         upper = np.array([140, 255, 255])\n",
    "#         mask = cv2.inRange(hsv, lower, upper)\n",
    "#         blueVal = float(mask.sum()) / float(max_value)\n",
    "#         if blueVal > 0.35:\n",
    "#             blue=\"true\"\n",
    "#         else:\n",
    "#             blue=\"false\"\n",
    "\n",
    "#         # detect green (gray)\n",
    "#         lower_green = np.array([103, 86, 65])\n",
    "#         upper_green = np.array([145, 133, 128])\n",
    "#         mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "#         greenVal = float(mask.sum()) / float(max_value)\n",
    "#         if greenVal > 0.01:\n",
    "#             green=\"true\"\n",
    "#         else:\n",
    "#             green=\"false\"\n",
    "\n",
    "#         # detect white\n",
    "#         lower = np.array([0, 0, 140])\n",
    "#         upper = np.array([256, 60, 256])\n",
    "#         mask = cv2.inRange(hsv, lower, upper)\n",
    "#         whiteVal = float(mask.sum()) / float(max_value)\n",
    "#         if whiteVal > 0.5:\n",
    "#             white=\"true\"\n",
    "#         else:\n",
    "#             white=\"false\"\n",
    "\n",
    "#         # detect black\n",
    "#         lower_black = np.array([110,50,50])\n",
    "#         upper_black= np.array([130,255,255])\n",
    "#         mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "#         blackVal = float(mask.sum()) / float(max_value)\n",
    "#         if blackVal > 0.01:\n",
    "#             black=\"true\"\n",
    "#         else:\n",
    "#             black=\"false\"\n",
    "\n",
    "#         return red, yellow, blue, green, white, black\n",
    "\n",
    "#     def color_detection_rgb(self, frame):\n",
    "#         # Take each frame\n",
    "#         #frame = cv2.imread(image_name)\n",
    "#         src_height, src_width, src_channels = frame.shape\n",
    "#         max_value = src_height * src_width * 255\n",
    "\n",
    "#         # Convert BGR to HSV\n",
    "#         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "# #         hsv = frame\n",
    "\n",
    "#         # detect red\n",
    "#         lower_red = np.array([17, 15, 100])\n",
    "#         upper_red = np.array([50, 56, 200])\n",
    "#         maskred = cv2.inRange(hsv, lower_red, upper_red)\n",
    "#         red = float(maskred.sum()) / float(max_value)\n",
    "\n",
    "#         # detect yellow\n",
    "#         lower_yellow = np.array([25, 146, 190])\n",
    "#         upper_yellow = np.array([62, 174, 250])\n",
    "#         mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "#         yellow = float(mask.sum()) / float(max_value)\n",
    "\n",
    "#         # detect blue\n",
    "#         lower_blue = np.array([86, 31, 4])\n",
    "#         upper_blue = np.array([220, 88, 50])\n",
    "#         mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "#         blue = float(mask.sum()) / float(max_value)\n",
    "\n",
    "#         # detect green (gray)\n",
    "#         #lower_green = np.array([103, 86, 65])\n",
    "#         #upper_green = np.array([145, 133, 128])\n",
    "#         #mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "#         #green = float(mask.sum()) / float(max_value)\n",
    "\n",
    "#         # detect white\n",
    "#         lower_white = np.array([103, 86, 65])\n",
    "#         upper_white = np.array([145, 133, 128])\n",
    "#         mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "#         white = float(mask.sum()) / float(max_value)\n",
    "\n",
    "#         # detect black\n",
    "#         #lower_blue = np.array([110,50,50])\n",
    "#         #upper_blue = np.array([130,255,255])\n",
    "#         #mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "#         #blue = float(mask.sum()) / float(max_value)\n",
    "\n",
    "#         return maskred, red, yellow, blue, float(0), white, float(0)\n",
    "    \n",
    "# # Webcamera no 0 is used to capture the frames \n",
    "# cap = cv2.VideoCapture(0) \n",
    "\n",
    "# # This drives the program into an infinite loop. \n",
    "# while(1):\t \n",
    "    \n",
    "#     # Captures the live stream frame-by-frame \n",
    "# #     _, frame = cap.read()\n",
    "#     _, frame = True, cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\color.png')\n",
    "\n",
    "#     p = PS_Search_Color(frame)\n",
    "    \n",
    "#     frame_in = frame\n",
    "#     print(p.color_detection(frame_in))\n",
    "#     print()\n",
    "#     maskred = p.color_detection_rgb(frame)[0]\n",
    "\n",
    "#     res = cv2.bitwise_and(frame,frame, mask= maskred)\n",
    "    \n",
    "#     cv2.imshow('frame',frame)\n",
    "# #     cv2.imshow('hsv',hsv)\n",
    "#     cv2.imshow('mask',maskred) \n",
    "#     cv2.imshow('res',res)\n",
    "    \n",
    "#     k = cv2.waitKey(5) & 0xFF\n",
    "#     if k == 27: # 27 means ESC button \n",
    "#         break\n",
    "\n",
    "# # Destroys all of the HighGUI windows. \n",
    "# cv2.destroyAllWindows() \n",
    "\n",
    "# # release the captured frame \n",
    "# cap.release() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroys all of the HighGUI windows. \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "# release the captured frame \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take each frame\n",
    "# frame_in = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\color.png')\n",
    "\n",
    "# src_height, src_width, src_channels = frame_in.shape\n",
    "# roiX = int(src_width / 4)\n",
    "# roiWidth = roiX * 2\n",
    "# roiY = src_height / 4\n",
    "# roiHeight = roiY * 2\n",
    "# # frame = frame_in[roiY : roiY+roiHeight, roiX : roiX+roiWidth]\n",
    "\n",
    "# src_height, src_width, src_channels = frame_in.shape\n",
    "# max_value = src_height * src_width * 255\n",
    "\n",
    "# # Convert BGR to HSV\n",
    "# hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# # detect red\n",
    "# lower = np.array([150, 30, 30])\n",
    "# upper = np.array([190, 255, 255])\n",
    "# mask1 = cv2.inRange(hsv, lower, upper)\n",
    "# lower = np.array([0, 30, 30])\n",
    "# upper = np.array([10, 255, 255])\n",
    "# mask2 = cv2.inRange(hsv, lower, upper)\n",
    "# mask = mask1 + mask2\n",
    "# redVal = float(mask.sum()) / float(max_value)\n",
    "# if redVal > 0.2:\n",
    "#     red=\"true\"\n",
    "# else:\n",
    "#     red=\"false\"\n",
    "    \n",
    "# print(red)\n",
    "    \n",
    "# # Take each frame\n",
    "# frame = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\color.png')\n",
    "\n",
    "# src_height, src_width, src_channels = frame.shape\n",
    "# max_value = src_height * src_width * 255\n",
    "\n",
    "# # Convert BGR to HSV\n",
    "# hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "# # hsv = frame\n",
    "\n",
    "# # detect red\n",
    "# lower_red = np.array([17, 15, 100])\n",
    "# upper_red = np.array([50, 56, 200])\n",
    "# mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "# red = float(mask.sum()) / float(max_value)\n",
    "\n",
    "# print(red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\gradient.png', 0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.subplot(2x1 vertical, 2x1 horizontal or a 2x2 grid, i'th box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Show only the object with the given color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "#     _, frame = cap.read()\n",
    "    _, img = True, cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\rgb.png')\n",
    "    \n",
    "    scale_percent = 90 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    frame = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "# Inside the while loop we define the HSV ranges (low_red, high_red),\n",
    "# we create the mask and we show only the object with the red color.\n",
    "\n",
    "    # Red color\n",
    "    low_red = np.array([161, 155, 84])\n",
    "    high_red = np.array([179, 255, 255])\n",
    "    red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "    red = cv2.bitwise_and(frame, frame, mask=red_mask)\n",
    "    \n",
    "# Same for the other colors:\n",
    "\n",
    "    # Blue color\n",
    "    low_blue = np.array([94, 80, 2])\n",
    "    high_blue = np.array([126, 255, 255])\n",
    "    blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "    blue = cv2.bitwise_and(frame, frame, mask=blue_mask)\n",
    "\n",
    "    # Green color\n",
    "    low_green = np.array([25, 52, 72])\n",
    "    high_green = np.array([102, 255, 255])\n",
    "    green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "    green = cv2.bitwise_and(frame, frame, mask=green_mask)\n",
    "\n",
    "    # Every color except white\n",
    "    low = np.array([0, 42, 0])\n",
    "    high = np.array([179, 255, 255])\n",
    "    mask = cv2.inRange(hsv_frame, low, high)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "# We finally show the result:\n",
    "\n",
    "    cv2.imshow(\"Frame (...press ESC to EXIT)\", frame)\n",
    "    cv2.imshow(\"Red\", red)\n",
    "    cv2.imshow(\"Blue\", blue)\n",
    "    cv2.imshow(\"Green\", green)\n",
    "    cv2.imshow(\"Result (...all color EXCEPT white)\", result)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xFF\n",
    "    if k == 27: # 27 means ESC button \n",
    "        break\n",
    "        \n",
    "# Destroys all of the HighGUI windows. \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# release the captured frame \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =====================================================================\n",
    "## https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html\n",
    "\n",
    "Mathematics\n",
    "The gradient of an image is a vector of its partials:\n",
    "\n",
    "### https://www.meccanismocomplesso.org/en/opencv-python-edge-detection-and-image-gradient-analysis/\n",
    "The calculation of the derivative – The derivative of Shobal and the Laplacian\n",
    "If you are interested in how you can calculate the derivative of a matrix you can read this section, otherwise you can go directly to the case study below.\n",
    "## ==========================[Latex mathematics]============================\n",
    "\n",
    "The derivative of a matrix is calculated by an operator called the Laplacian, in honor of Laplace, a famous mathematician.\n",
    "\n",
    " \\Delta src = \\frac{\\partial ^2{src}}{\\partial x^2} + \\frac{\\partial ^2{src}}{\\partial y^2} \n",
    "\n",
    "Unfortunately the partial derivatives can not be solved analytically but must be treated with the numerical calculation using approximations. So if you want to calculate a Laplacian, you will need to calculate first two derivatives, called derivatives of Sobal, each of which takes into account the gradient variations in a certain direction: one horizontal, the other vertical.\n",
    "\n",
    "horizontal derivative of Sobal (Sobal x). Is obtained through the convolution * The image with a matrix  G_ {x}  kernel call always odd sizes. The simplest case, the one with the size 3 kernel is the following case:\n",
    "\n",
    "Horizontal Sobal derivative (Sobal x). It is obtained through the convolution  * of the image I with a matrix  G_{x} called kernel which has always odd size. The kernel with size 3 is the simplest case:\n",
    "\n",
    " G_{x} = \\begin{bmatrix} -1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1 \\end{bmatrix} * I \n",
    "\n",
    "Vertical Sobal derivative (Sobal y). It is obtained through the convolution * of the image I with a matrix $latex G_{y} $ called kernel which has always odd size. The kernel with size 3 is the simplest case:\n",
    "\n",
    " G_{y} = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +2 & +1 \\end{bmatrix} * I \n",
    "\n",
    "So in the end to get the Laplacian (approximation) you will need to combine the two previous results\n",
    "\n",
    " G = \\sqrt{ G_{x}^{2} + G_{y}^{2} } \n",
    "\n",
    "although sometimes you’d prefer to also simplify this equation:\n",
    "\n",
    " G = |G_{x}| + |G_{y}| \n",
    "\n",
    "The lower the size of the kernel, the greater the approximation with which you’ll get the results. But at the same time the larger the size of the kernel the greater the required calculation. For a kernel size 3, however, the approximation can be really excessive, and it is better to use the Scharr function (also available in OpenCV). As for the examples in this article, you will use a size 5 kernel that is a good compromise calculation-approximation.\n",
    "\n",
    "\n",
    "The Scharr function has these two kernels:\n",
    "\n",
    " G_{x} = \\begin{bmatrix} -3 & 0 & +3 \\\\ -10 & 0 & +10 \\\\ -3 & 0 & +3 \\end{bmatrix} G_{y} = \\begin{bmatrix} -3 & -10 & -3 \\\\ 0 & 0 & 0 \\\\ +3 & +10 & +3 \\end{bmatrix} \n",
    " \n",
    "##### ===================================================================================================================\n",
    " \n",
    "## Gaussian filter\n",
    "\n",
    "The image after a 5×5 Gaussian mask has been passed across each pixel.\n",
    "Since all edge detection results are easily affected by the noise in the image, it is essential to filter out the noise to prevent false detection caused by it. To smooth the image, a Gaussian filter kernel is convolved with the image. This step will slightly smooth the image to reduce the effects of obvious noise on the edge detector. The equation for a Gaussian filter kernel of size (2k+1)×(2k+1) is given by:\n",
    "\n",
    "{\\displaystyle H_{ij}={\\frac {1}{2\\pi \\sigma ^{2}}}\\exp \\left(-{\\frac {(i-(k+1))^{2}+(j-(k+1))^{2}}{2\\sigma ^{2}}}\\right);1\\leq i,j\\leq (2k+1)}{\\displaystyle H_{ij}={\\frac {1}{2\\pi \\sigma ^{2}}}\\exp \\left(-{\\frac {(i-(k+1))^{2}+(j-(k+1))^{2}}{2\\sigma ^{2}}}\\right);1\\leq i,j\\leq (2k+1)}\n",
    "\n",
    "Here is an example of a 5×5 Gaussian filter, used to create the adjacent image, with {\\displaystyle \\sigma }\\sigma  = 1.4. (The asterisk denotes a convolution operation.)\n",
    "\n",
    "{\\displaystyle \\mathbf {B} ={\\frac {1}{159}}{\\begin{bmatrix}2&4&5&4&2\\\\4&9&12&9&4\\\\5&12&15&12&5\\\\4&9&12&9&4\\\\2&4&5&4&2\\end{bmatrix}}*\\mathbf {A} .}\\mathbf {B} ={\\frac {1}{159}}{\\begin{bmatrix}2&4&5&4&2\\\\4&9&12&9&4\\\\5&12&15&12&5\\\\4&9&12&9&4\\\\2&4&5&4&2\\end{bmatrix}}*\\mathbf {A} .\n",
    "It is important to understand that the selection of the size of the Gaussian kernel will affect the performance of the detector. The larger the size is, the lower the detector's sensitivity to noise. Additionally, the localization error to detect the edge will slightly increase with the increase of the Gaussian filter kernel size. A 5×5 is a good size for most cases, but this will also vary depending on specific situations.\n",
    "\n",
    "## Finding the intensity gradient of the image\n",
    "An edge in an image may point in a variety of directions, so the Canny algorithm uses four filters to detect horizontal, vertical and diagonal edges in the blurred image. The edge detection operator (such as Roberts, Prewitt, or Sobel) returns a value for the first derivative in the horizontal direction (Gx) and the vertical direction (Gy). From this the edge gradient and direction can be determined:\n",
    "\n",
    "{\\displaystyle \\mathbf {G} ={\\sqrt {{\\mathbf {G} _{x}}^{2}+{\\mathbf {G} _{y}}^{2}}}}\\mathbf {G} ={\\sqrt {{\\mathbf {G} _{x}}^{2}+{\\mathbf {G} _{y}}^{2}}}\n",
    "{\\displaystyle \\mathbf {\\Theta } =\\operatorname {atan2} \\left(\\mathbf {G} _{y},\\mathbf {G} _{x}\\right)}\\mathbf {\\Theta } =\\operatorname {atan2} \\left(\\mathbf {G} _{y},\\mathbf {G} _{x}\\right),\n",
    "where G can be computed using the hypot function and atan2 is the arctangent function with two arguments. The edge direction angle is rounded to one of four angles representing vertical, horizontal and the two diagonals (0°, 45°, 90° and 135°). An edge direction falling in each color region will be set to a specific angle values, for instance θ in [0°, 22.5°] or [157.5°, 180°] maps to 0°.\n",
    " \n",
    "# OpenCV program to perform Edge detection in real time... using cv2.Canny\n",
    "### https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries of python OpenCV \n",
    "# where its functionality resides\n",
    "\n",
    "# ........................................................................................................ #\n",
    "\n",
    "import cv2 \n",
    "\n",
    "# np is an alias pointing to numpy library \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "# capture frames from a camera \n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "\n",
    "# loop runs if capturing has been initialized \n",
    "while(1): \n",
    "\n",
    "    # reads frames from a camera \n",
    "    ret, frame = cap.read() \n",
    "\n",
    "    # converting BGR to HSV \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "    cv2.imshow('HSV',hsv)\n",
    "\n",
    "    # define range of red color in HSV \n",
    "    lower_red = np.array([30,150,50]) \n",
    "    upper_red = np.array([255,255,180]) \n",
    "\n",
    "    # create a red HSV colour boundary and \n",
    "    # threshold HSV image \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red) \n",
    "\n",
    "    # Bitwise-AND mask and original image \n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask) \n",
    "\n",
    "    # Display an original image \n",
    "    cv2.imshow('Original',frame) \n",
    "\n",
    "    # finds edges in the input image image and \n",
    "    # marks them in the output map edges \n",
    "    edges = cv2.Canny(frame,100,200) # ..............................<<<<<<<<<<<<......................................\n",
    "\n",
    "    # Display edges in a frame \n",
    "    cv2.imshow('Edges (...press ESC to close)',edges) \n",
    "\n",
    "    # Wait for Esc key to stop \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27: # ESC is 27 \n",
    "        break\n",
    "\n",
    "\n",
    "# Close the window \n",
    "cap.release() \n",
    "\n",
    "# De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is mask in OpenCV?\n",
    "\n",
    "### In OpenCV, a mask image is of type uint8_t . Pixels of value 0xFF are true and pixels of value 0 are false. A mask can be applied on an image of the same dimensions, but of any type. By applying a mask M on an image I , the pixels of I whose corresponding pixel in M are true are copied into a new image.\n",
    "\n",
    "## Sobel Derivatives\n",
    "### https://docs.opencv.org/3.4/d2/d2c/tutorial_sobel_derivatives.html\n",
    "## Book by Adrian Kaehler and Gary Bradski : https://g.co/kgs/Mg2bKu\n",
    "\n",
    "## Laplace Operator\n",
    "### https://docs.opencv.org/3.4/d5/db5/tutorial_laplace_operator.html\n",
    "\n",
    "# Gradient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    laplacian = cv2.Laplacian(frame,cv2.CV_64F)\n",
    "    sobelx = cv2.Sobel(frame,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobely = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "    cv2.imshow('Original',frame)\n",
    "    cv2.imshow('Mask',mask)\n",
    "    cv2.imshow('laplacian',laplacian)\n",
    "    cv2.imshow('sobelx',sobelx)\n",
    "    cv2.imshow('sobely',sobely)\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting... gradients to pure Edges\n",
    "## Canny Edge Detector\n",
    "### https://docs.opencv.org/3.4/da/d5c/tutorial_canny_detector.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('Original',frame)\n",
    "    edges = cv2.Canny(frame,100,200)\n",
    "    cv2.imshow('Edges',edges)\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Line Transform\n",
    "## https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html\n",
    "\n",
    "The Hough Line Transform is a transform used to detect straight lines.\n",
    "To apply the Transform, first an edge detection pre-processing is desirable.\n",
    "How does it work?\n",
    "As you know, a line in the image space can be expressed with two variables. For example:\n",
    "\n",
    "What does all the stuff above mean? It means that in general, a line can be detected by finding the number of intersections between curves.The more curves intersecting means that the line represented by that intersection have more points. In general, we can define a threshold of the minimum number of intersections needed to detect a line.\n",
    "This is what the Hough Line Transform does. It keeps track of the intersection between curves of every point in the image. If the number of intersections is above some threshold, then it declares it as a line with the parameters (θ,rθ) of the intersection point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import math\n",
    "# import cv2 as cv\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def main(argv):\n",
    "#     ## [load]\n",
    "#     default_file = r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\table.png'\n",
    "#     filename = argv[0] if len(argv) > 0 else default_file\n",
    "\n",
    "#     # Loads an image\n",
    "#     src = cv.imread(cv.samples.findFile(filename), cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "#     # Check if image is loaded fine\n",
    "#     if src is None:\n",
    "#         print ('Error opening image!')\n",
    "#         print ('Usage: hough_lines.py [image_name -- default ' + default_file + '] \\n')\n",
    "#         return -1\n",
    "#     ## [load]\n",
    "\n",
    "#     ## [edge_detection]\n",
    "#     # Edge detection\n",
    "#     dst = cv.Canny(src, 50, 200, None, 3)\n",
    "#     ## [edge_detection]\n",
    "\n",
    "#     # Copy edges to the images that will display the results in BGR\n",
    "#     cdst = cv.cvtColor(dst, cv.COLOR_GRAY2BGR)\n",
    "#     cdstP = np.copy(cdst)\n",
    "\n",
    "#     ## [hough_lines]\n",
    "#     #  Standard Hough Line Transform\n",
    "#     lines = cv.HoughLines(dst, 1, np.pi / 180, 150, None, 0, 0)\n",
    "#     ## [hough_lines]\n",
    "#     ## [draw_lines]\n",
    "#     # Draw the lines\n",
    "#     if lines is not None:\n",
    "#         for i in range(0, len(lines)):\n",
    "#             rho = lines[i][0][0]\n",
    "#             theta = lines[i][0][1]\n",
    "#             a = math.cos(theta)\n",
    "#             b = math.sin(theta)\n",
    "#             x0 = a * rho\n",
    "#             y0 = b * rho\n",
    "#             pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "#             pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "\n",
    "#             cv.line(cdst, pt1, pt2, (0,0,255), 3, cv.LINE_AA)\n",
    "#     ## [draw_lines]\n",
    "\n",
    "#     ## [hough_lines_p]\n",
    "#     # Probabilistic Line Transform\n",
    "#     linesP = cv.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10)\n",
    "#     ## [hough_lines_p]\n",
    "#     ## [draw_lines_p]\n",
    "#     # Draw the lines\n",
    "#     if linesP is not None:\n",
    "#         for i in range(0, len(linesP)):\n",
    "#             l = linesP[i][0]\n",
    "#             cv.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv.LINE_AA)\n",
    "#     ## [draw_lines_p]\n",
    "#     ## [imshow]\n",
    "#     # Show results\n",
    "#     cv.imshow(\"Source\", src)\n",
    "#     cv.imshow(\"Detected Lines (in red) - Standard Hough Line Transform\", cdst)\n",
    "#     cv.imshow(\"Detected Lines (in red) - Probabilistic Line Transform\", cdstP)\n",
    "#     ## [imshow]\n",
    "#     ## [exit]\n",
    "#     # Wait and Exit\n",
    "#     cv.waitKey()\n",
    "#     return 0\n",
    "#     ## [exit]\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Color with OpenCV\n",
    "## https://www.geeksforgeeks.org/filter-color-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while(1):\n",
    "    \n",
    "    _, frame = cap.read() \n",
    "    # It converts the BGR color space of image to HSV color space \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "    # Threshold of blue in HSV space \n",
    "    lower_blue = np.array([35, 140, 60]) \n",
    "    upper_blue = np.array([255, 255, 180])\n",
    "    \n",
    "    # Threshold of red in HSV space \n",
    "    lower_red = np.array([110,50,50])\n",
    "    upper_red = np.array([130,255,255])\n",
    "\n",
    "    # preparing the mask to overlay \n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # The black region in the mask has the value of 0, \n",
    "    # so when multiplied with original image removes all non-blue regions \n",
    "    result = cv2.bitwise_and(frame, frame, mask = mask) \n",
    "\n",
    "    cv2.imshow('frame', frame) \n",
    "    cv2.imshow('blue mask', mask_blue)\n",
    "    cv2.imshow('red mask', mask_red) \n",
    "    cv2.imshow('result', result) \n",
    "\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "    # Wait for Esc key to stop \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27: # ESC is 27 \n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "cap.release() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mr. INDIA... Invisible Cloak using OpenCV\n",
    "## https://www.geeksforgeeks.org/invisible-cloak-using-opencv-python-project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import time \n",
    "\n",
    "# replace the red pixels ( or undesired area ) with \n",
    "# background pixels to generate the invisibility feature. \n",
    "\n",
    "## 1. Hue: This channel encodes color information. Hue can be \n",
    "# thought of an angle where 0 degree corresponds to the red color, \n",
    "# 120 degrees corresponds to the green color, and 240 degrees \n",
    "# corresponds to the blue color. \n",
    "\n",
    "## 2. Saturation: This channel encodes the intensity/purity of color. \n",
    "# For example, pink is less saturated than red. \n",
    "\n",
    "## 3. Value: This channel encodes the brightness of color. \n",
    "# Shading and gloss components of an image appear in this \n",
    "# channel reading the videocapture video \n",
    "\n",
    "# in order to check the cv2 version \n",
    "print(cv2.__version__)  \n",
    "\n",
    "capture_video = cv2.VideoCapture(0) \n",
    "\n",
    "# give the camera to warm up \n",
    "time.sleep(1) \n",
    "count = 0\n",
    "background = 0\n",
    "\n",
    "# capturing the background in range of 60 \n",
    "# you should have video that have some seconds \n",
    "# dedicated to background frame so that it \n",
    "# could easily save the background image \n",
    "for i in range(60): \n",
    "    return_val, background = capture_video.read() \n",
    "    if return_val == False : \n",
    "        continue\n",
    "\n",
    "background = np.flip(background, axis = 1) # flipping of the frame \n",
    "\n",
    "# we are reading from video \n",
    "while (capture_video.isOpened()):\n",
    "    \n",
    "    return_val, img = capture_video.read() \n",
    "    if not return_val : \n",
    "        break\n",
    "    count = count + 1\n",
    "    img = np.flip(img, axis = 1) \n",
    "\n",
    "    # convert the image - BGR to HSV \n",
    "    # as we focused on detection of red color \n",
    "\n",
    "    # converting BGR to HSV for better \n",
    "    # detection or you can convert it to gray \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "    #-------------------------------------BLOCK----------------------------# \n",
    "    # ranges should be carefully chosen \n",
    "    # setting the lower and upper range for mask1 \n",
    "    lower_red = np.array([100, 40, 40]) \n",
    "    upper_red = np.array([100, 255, 255]) \n",
    "    mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # setting the lower and upper range for mask2 \n",
    "    lower_red = np.array([155, 40, 40]) \n",
    "    upper_red = np.array([180, 255, 255]) \n",
    "    mask2 = cv2.inRange(hsv, lower_red, upper_red) \n",
    "    #----------------------------------------------------------------------# \n",
    "\n",
    "    # the above block of code could be replaced with \n",
    "    # some other code depending upon the color of your cloth \n",
    "    mask1 = mask1 + mask2 \n",
    "\n",
    "    # Refining the mask corresponding to the detected red color \n",
    "    mask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, np.ones((3, 3), \n",
    "                                        np.uint8), iterations = 2) \n",
    "    mask1 = cv2.dilate(mask1, np.ones((3, 3), np.uint8), iterations = 1) \n",
    "    mask2 = cv2.bitwise_not(mask1) \n",
    "\n",
    "    # Generating the final output \n",
    "    res1 = cv2.bitwise_and(background, background, mask = mask1) \n",
    "    res2 = cv2.bitwise_and(img, img, mask = mask2) \n",
    "\n",
    "    final_output = cv2.addWeighted(res1, 1, res2, 1, 0) \n",
    "\n",
    "    cv2.imshow(\"INVISIBLE MAN\", final_output) \n",
    "    k = cv2.waitKey(30) & 0xFF\n",
    "    if k == 27: \n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows() \n",
    "capture_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining each step shell by shell of Mr. INDIA code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " <VideoCapture 0000022A6C41DA90>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import time \n",
    "\n",
    "capture_video = cv2.VideoCapture(0) \n",
    "\n",
    "# give the camera to warm up \n",
    "time.sleep(1) \n",
    "count = 0\n",
    "background = 0\n",
    " \n",
    "for i in range(60): \n",
    "    return_val, background = capture_video.read() \n",
    "    if return_val == False : \n",
    "        continue\n",
    "\n",
    "background = np.flip(background, axis = 1) # flipping of the frame \n",
    "\n",
    "cv2.imshow('Flipped image, axis = 1 = (vertical)', background)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "background, capture_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are reading from video \n",
    "# while (capture_video.isOpened()):\n",
    "    \n",
    "capture_video.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 3,\n",
       " True,\n",
       " array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to run this sgell go 2 shell up, as destroyed_all_windows...\n",
    "\n",
    "return_val, img = capture_video.read() \n",
    "\n",
    "# if not return_val : \n",
    "#     break\n",
    "    \n",
    "count = count + 1\n",
    "cv2.imshow('Original image (...PRESS ESC to EXIT)', img)\n",
    "\n",
    "img = np.flip(img, axis = 1) \n",
    "\n",
    "cv2.imshow('Flipped image, axis = 1 = (vertical)', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "# capture_video.release() # this shut down LED beside of webcam\n",
    "\n",
    "return_val, count, capture_video.isOpened(), img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flip an image\n",
    "## https://techtutorialsx.com/2019/04/21/python-opencv-flipping-an-image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...PRESS ESC to EXIT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "originalImage = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\thali bajana.jpg')\n",
    "  \n",
    "flipVertical = cv2.flip(originalImage, 0)\n",
    "flipHorizontal = cv2.flip(originalImage, 1)\n",
    "flipBoth = cv2.flip(originalImage, -1)\n",
    "\n",
    "print('...PRESS ESC to EXIT')\n",
    "cv2.imshow('Original image (...PRESS ESC to EXIT)', originalImage)\n",
    "cv2.imshow('Flipped vertical image', flipVertical)\n",
    "cv2.imshow('Flipped horizontal image', flipHorizontal)\n",
    "cv2.imshow('Flipped both image', flipBoth)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Mr. INDIA...) to be cont. =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image - BGR to HSV \n",
    "# as we focused on detection of red color \n",
    "\n",
    "# converting BGR to HSV for better \n",
    "# detection or you can convert it to gray \n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "cv2.imshow('HSV image', hsv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([100,  40,  40]),\n",
       " array([100, 255, 255]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------BLOCK----------------------------# \n",
    "# ranges should be carefully chosen \n",
    "# setting the lower and upper range for mask1 \n",
    "\n",
    "lower_red = np.array([100, 40, 40]) \n",
    "upper_red = np.array([100, 255, 255]) \n",
    "mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "cv2.imshow('Mask1 image (...press ESC to EXIT)', mask1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "lower_red, upper_red, mask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([155,  40,  40]),\n",
       " array([180, 255, 255]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the lower and upper range for mask2 \n",
    "\n",
    "lower_red = np.array([155, 40, 40]) \n",
    "upper_red = np.array([180, 255, 255]) \n",
    "mask2 = cv2.inRange(hsv, lower_red, upper_red) \n",
    "\n",
    "cv2.imshow('Mask2 image (...press ESC to EXIT)', mask2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "lower_red, upper_red, mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------# \n",
    "\n",
    "# the above block of code could be replaced with \n",
    "# some other code depending upon the color of your cloth \n",
    "mask = mask1 + mask2 \n",
    "\n",
    "cv2.imshow('Resultant Mask image (...press ESC to EXIT)', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "mask, type(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refining the mask corresponding to the detected red color \n",
    "mask_morphologyEx = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations = 2)\n",
    "\n",
    "cv2.imshow('Mask_morphologyEx image (...press ESC to EXIT)', mask_morphologyEx)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "mask_morphologyEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_dilate = cv2.dilate(mask_morphologyEx, np.ones((3, 3), np.uint8), iterations = 1) \n",
    "\n",
    "cv2.imshow('Mask_dilate image (...press ESC to EXIT)', mask_dilate)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "mask_dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_bitwise_not = cv2.bitwise_not(mask_dilate) \n",
    "\n",
    "cv2.imshow('Mask_bitwise_not image (...press ESC to EXIT)', mask_bitwise_not)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "mask_bitwise_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating the final output \n",
    "res1 = cv2.bitwise_and(background, background, mask = mask_bitwise_not) \n",
    "\n",
    "cv2.imshow('Mask_bitwise_and of background image (...press ESC to EXIT)', res1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = cv2.bitwise_and(img, img, mask = mask2) \n",
    "\n",
    "cv2.imshow('Mask_bitwise_and of Original (read) image (...press ESC to EXIT)', res2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = cv2.addWeighted(res1, 1, res2, 1, 0)\n",
    "\n",
    "cv2.imshow(\"INVISIBLE MAN\", final_output) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "final_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     k = cv2.waitKey(30) & 0xFF\n",
    "#     if k == 27: \n",
    "#         break\n",
    "        \n",
    "daw = cv2.destroyAllWindows() \n",
    "rls = capture_video.release()\n",
    "\n",
    "daw, rls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Program illustrating >> numpy.flip() << method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of n dimentional array :  (453, 725, 3)\n",
      ".............................\n",
      "\n",
      "Flipped array, axis = 0 : \n",
      "\n",
      " [[[12 25 57]\n",
      "  [12 26 55]\n",
      "  [17 28 58]\n",
      "  ...\n",
      "  [85 67 68]\n",
      "  [87 69 70]\n",
      "  [87 69 70]]\n",
      "\n",
      " [[15 28 60]\n",
      "  [14 28 57]\n",
      "  [18 29 59]\n",
      "  ...\n",
      "  [72 54 55]\n",
      "  [74 56 57]\n",
      "  [74 56 57]]\n",
      "\n",
      " [[20 33 65]\n",
      "  [18 32 61]\n",
      "  [19 30 60]\n",
      "  ...\n",
      "  [41 23 24]\n",
      "  [44 26 27]\n",
      "  [45 27 28]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[66 52 53]\n",
      "  [67 53 54]\n",
      "  [66 52 53]\n",
      "  ...\n",
      "  [21  4 15]\n",
      "  [23  6 17]\n",
      "  [23  6 17]]\n",
      "\n",
      " [[67 53 55]\n",
      "  [67 53 55]\n",
      "  [66 52 54]\n",
      "  ...\n",
      "  [25  9 20]\n",
      "  [27 11 22]\n",
      "  [27 11 22]]\n",
      "\n",
      " [[66 52 54]\n",
      "  [67 53 55]\n",
      "  [65 51 53]\n",
      "  ...\n",
      "  [30 14 25]\n",
      "  [31 15 26]\n",
      "  [32 16 27]]]\n",
      ".............................\n",
      "\n",
      "Flipped array, axis = 1 : \n",
      "\n",
      " [[[32 16 27]\n",
      "  [31 15 26]\n",
      "  [30 14 25]\n",
      "  ...\n",
      "  [65 51 53]\n",
      "  [67 53 55]\n",
      "  [66 52 54]]\n",
      "\n",
      " [[27 11 22]\n",
      "  [27 11 22]\n",
      "  [25  9 20]\n",
      "  ...\n",
      "  [66 52 54]\n",
      "  [67 53 55]\n",
      "  [67 53 55]]\n",
      "\n",
      " [[23  6 17]\n",
      "  [23  6 17]\n",
      "  [21  4 15]\n",
      "  ...\n",
      "  [66 52 53]\n",
      "  [67 53 54]\n",
      "  [66 52 53]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[45 27 28]\n",
      "  [44 26 27]\n",
      "  [41 23 24]\n",
      "  ...\n",
      "  [19 30 60]\n",
      "  [18 32 61]\n",
      "  [20 33 65]]\n",
      "\n",
      " [[74 56 57]\n",
      "  [74 56 57]\n",
      "  [72 54 55]\n",
      "  ...\n",
      "  [18 29 59]\n",
      "  [14 28 57]\n",
      "  [15 28 60]]\n",
      "\n",
      " [[87 69 70]\n",
      "  [87 69 70]\n",
      "  [85 67 68]\n",
      "  ...\n",
      "  [17 28 58]\n",
      "  [12 26 55]\n",
      "  [12 25 57]]]\n",
      ".............................\n",
      "\n",
      "Flipped array, axis = None : \n",
      "\n",
      " [[[70 69 87]\n",
      "  [70 69 87]\n",
      "  [68 67 85]\n",
      "  ...\n",
      "  [58 28 17]\n",
      "  [55 26 12]\n",
      "  [57 25 12]]\n",
      "\n",
      " [[57 56 74]\n",
      "  [57 56 74]\n",
      "  [55 54 72]\n",
      "  ...\n",
      "  [59 29 18]\n",
      "  [57 28 14]\n",
      "  [60 28 15]]\n",
      "\n",
      " [[28 27 45]\n",
      "  [27 26 44]\n",
      "  [24 23 41]\n",
      "  ...\n",
      "  [60 30 19]\n",
      "  [61 32 18]\n",
      "  [65 33 20]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[17  6 23]\n",
      "  [17  6 23]\n",
      "  [15  4 21]\n",
      "  ...\n",
      "  [53 52 66]\n",
      "  [54 53 67]\n",
      "  [53 52 66]]\n",
      "\n",
      " [[22 11 27]\n",
      "  [22 11 27]\n",
      "  [20  9 25]\n",
      "  ...\n",
      "  [54 52 66]\n",
      "  [55 53 67]\n",
      "  [55 53 67]]\n",
      "\n",
      " [[27 16 32]\n",
      "  [26 15 31]\n",
      "  [25 14 30]\n",
      "  ...\n",
      "  [53 51 65]\n",
      "  [55 53 67]\n",
      "  [54 52 66]]]\n",
      ".............................\n",
      "\n",
      "Original array : \n",
      "\n",
      " [[[66 52 54]\n",
      "  [67 53 55]\n",
      "  [65 51 53]\n",
      "  ...\n",
      "  [30 14 25]\n",
      "  [31 15 26]\n",
      "  [32 16 27]]\n",
      "\n",
      " [[67 53 55]\n",
      "  [67 53 55]\n",
      "  [66 52 54]\n",
      "  ...\n",
      "  [25  9 20]\n",
      "  [27 11 22]\n",
      "  [27 11 22]]\n",
      "\n",
      " [[66 52 53]\n",
      "  [67 53 54]\n",
      "  [66 52 53]\n",
      "  ...\n",
      "  [21  4 15]\n",
      "  [23  6 17]\n",
      "  [23  6 17]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[20 33 65]\n",
      "  [18 32 61]\n",
      "  [19 30 60]\n",
      "  ...\n",
      "  [41 23 24]\n",
      "  [44 26 27]\n",
      "  [45 27 28]]\n",
      "\n",
      " [[15 28 60]\n",
      "  [14 28 57]\n",
      "  [18 29 59]\n",
      "  ...\n",
      "  [72 54 55]\n",
      "  [74 56 57]\n",
      "  [74 56 57]]\n",
      "\n",
      " [[12 25 57]\n",
      "  [12 26 55]\n",
      "  [17 28 58]\n",
      "  ...\n",
      "  [85 67 68]\n",
      "  [87 69 70]\n",
      "  [87 69 70]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as geek\n",
    "import cv2\n",
    "\n",
    "# array = geek.arange(0,8,1).reshape((2,2,2))\n",
    "array = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\thali bajana.jpg')\n",
    "\n",
    "print('Shape of n dimentional array : ', array.shape)\n",
    "\n",
    "f0 = geek.flip(array, axis = 0)\n",
    "f1 = geek.flip(array, axis = 1)\n",
    "fb = geek.flip(array, axis = None)\n",
    "\n",
    "print(\".............................\\n\\nFlipped array, axis = 0 : \\n\\n\", f0) \n",
    "print(\".............................\\n\\nFlipped array, axis = 1 : \\n\\n\", f1)\n",
    "print(\".............................\\n\\nFlipped array, axis = None : \\n\\n\", fb)\n",
    "print(\".............................\\n\\nOriginal array : \\n\\n\", array)\n",
    "\n",
    "cv2.imshow('Flipped axis = 0, (horizontal mirror image)', f0)\n",
    "cv2.imshow('Flipped axis = 1, (vertical mirror image)', f1)\n",
    "cv2.imshow('Flipped axis = None, (both mirror image)', fb)\n",
    "cv2.imshow('Original image', array)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic Operations on Images (Bitwise Operations on Binary Images)\n",
    "## https://www.geeksforgeeks.org/arithmetic-operations-on-images-using-opencv-set-2-bitwise-operations-on-binary-images/\n",
    "\n",
    "## Syntax : cv2.bitwise_and(source1, source2, destination, mask)\n",
    "\n",
    "## Parameters :\n",
    "## source1: First Input Image array(Single-channel, 8-bit or floating-point)\n",
    "## source2: Second Input Image array(Single-channel, 8-bit or floating-point)\n",
    "## dest: Output array (Similar to the dimensions and type of Input image array)\n",
    "## mask: Operation mask, Input / output 8-bit single-channel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python programe to illustrate \n",
    "# arithmetic operation of \n",
    "# bitwise AND of two images, \n",
    "# bitwise OR of two images,\n",
    "# bitwise XOR of two images,\n",
    "# bitwise NOT on input image \n",
    "\n",
    "# organizing imports \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# path to input images are specified and \n",
    "# images are loaded with imread command \n",
    "img1 = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\baw.png') \n",
    "img2 = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\bawc.png') \n",
    "\n",
    "cv2.imshow('Black and White Frame', img1) \n",
    "cv2.imshow('Black and White Center', img2)\n",
    "\n",
    "# cv2.bitwise_not is applied over the \n",
    "# image input with applied parameters \n",
    "dest_not1 = cv2.bitwise_not(img1, mask = None) \n",
    "dest_not2 = cv2.bitwise_not(img2, mask = None) \n",
    "\n",
    "# the windows showing output image \n",
    "# with the Bitwise NOT operation \n",
    "# on the 1st and 2nd input image \n",
    "cv2.imshow('Bitwise NOT on image 1', dest_not1) \n",
    "cv2.imshow('Bitwise NOT on image 2', dest_not2)\n",
    "\n",
    "# cv2.bitwise_and is applied over the \n",
    "# image inputs with applied parameters \n",
    "dest_and = cv2.bitwise_and(img2, img1, mask = None)\n",
    "\n",
    "# cv2.bitwise_or is applied over the \n",
    "# image inputs with applied parameters  \n",
    "dest_or = cv2.bitwise_or(img2, img1, mask = None)\n",
    "\n",
    "# cv2.bitwise_xor is applied over the \n",
    "# image inputs with applied parameters \n",
    "dest_xor = cv2.bitwise_xor(img1, img2, mask = None)\n",
    "\n",
    "# the window showing output image \n",
    "# with the Bitwise AND operation \n",
    "# on the input images \n",
    "cv2.imshow('Bitwise And', dest_and) \n",
    "\n",
    "# the window showing output image \n",
    "# with the Bitwise OR operation \n",
    "# on the input images \n",
    "cv2.imshow('Bitwise OR', dest_or)\n",
    "\n",
    "# the window showing output image \n",
    "# with the Bitwise XOR operation \n",
    "# on the input images \n",
    "cv2.imshow('Bitwise XOR', dest_xor)\n",
    "\n",
    "# De-allocate any associated memory usage \n",
    "if cv2.waitKey(0) & 0xff == 27: # Press ESC to exit\n",
    "    cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic Operations on Images (Addition and Subtraction)\n",
    "## https://www.geeksforgeeks.org/arithmetic-operations-on-images-using-opencv-set-1-addition-and-subtraction/\n",
    "\n",
    "# Syntax: cv2.addWeighted(img1, wt1, img2, wt2, gammaValue)\n",
    "# Syntax:  cv2.subtract(src1, src2)\n",
    "\n",
    "## Parameters:\n",
    "## img1: First Input Image array(Single-channel, 8-bit or floating-point)\n",
    "## wt1: Weight of the first input image elements to be applied to the final image\n",
    "## img2: Second Input Image array(Single-channel, 8-bit or floating-point)\n",
    "## wt2: Weight of the second input image elements to be applied to the final image\n",
    "## gammaValue: Measurement of light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "But adding the pixels is not an ideal situation.\n",
      "So, we use cv2.addweighted().\n",
      "Remember, both images should be of equal size and depth.\n",
      "\n",
      "Just like addition, we can subtract the pixel values in two images and\n",
      "merge them with the help of cv2.subtract().\n",
      "The images should be of equal size and depth.\n",
      "\n",
      "\n",
      "Image ones Shape :  (250, 500, 3)\n",
      "Image twos Shape :  (250, 500, 3)\n",
      "Weighted Images Shape :  (250, 500, 3)\n",
      "Subtracted Images Shape :  (250, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Python programe to illustrate \n",
    "# arithmetic operation of \n",
    "# addition of two images,\n",
    "# subtraction of pixels of two images \n",
    "\n",
    "# organizing imports \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# path to input images are specified and \n",
    "# images are loaded with imread command \n",
    "image1 = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\one.png') \n",
    "image2 = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\two.png') \n",
    "\n",
    "print('''\n",
    "\n",
    "But adding the pixels is not an ideal situation.\n",
    "So, we use cv2.addweighted().\n",
    "Remember, both images should be of equal size and depth.\n",
    "\n",
    "Just like addition, we can subtract the pixel values in two images and\n",
    "merge them with the help of cv2.subtract().\n",
    "The images should be of equal size and depth.\n",
    "\n",
    "''')\n",
    "\n",
    "# the window showing image one\n",
    "cv2.imshow('Image One', image1)\n",
    "print('Image one''s Shape : ', image1.shape)\n",
    "\n",
    "# the window showing image two\n",
    "cv2.imshow('Image Two', image2)\n",
    "print('Image two''s Shape : ', image2.shape)\n",
    "\n",
    "# cv2.addWeighted is applied over the \n",
    "# image inputs with applied parameters \n",
    "weightedSum = cv2.addWeighted(image1, 0.5, image2, 0.4, 0) \n",
    "\n",
    "# the window showing output image \n",
    "# with the weighted sum \n",
    "cv2.imshow('Weighted Image', weightedSum)\n",
    "print('Weighted Image''s Shape : ', weightedSum.shape)\n",
    "\n",
    "# cv2.subtract is applied over the \n",
    "# image inputs with applied parameters \n",
    "sub = cv2.subtract(image1, image2) \n",
    "\n",
    "# the window showing output image \n",
    "# with the subtracted image \n",
    "cv2.imshow('Subtracted Image', sub)\n",
    "print('Subtracted Image''s Shape : ', sub.shape)\n",
    "\n",
    "# De-allocate any associated memory usage \n",
    "if cv2.waitKey(0) & 0xff == 27: \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Drawing and Writing on Image\n",
    "## https://pythonprogramming.net/drawing-writing-python-opencv-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(r'C:\\Users\\Vicky Kumar\\Pictures\\Saved Pictures\\aryadp.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.line(img,(0,0),(200,300),(255,255,255),50)\n",
    "cv2.rectangle(img,(500,250),(1000,500),(0,0,255),15)\n",
    "cv2.circle(img,(447,63), 63, (0,255,0), -1)\n",
    "\n",
    "pts = np.array([[100,50],[200,300],[700,200],[500,100]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img, [pts], True, (0,255,255), 3)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,'OpenCV Tuts!',(10,500), font, 6, (200,255,155), 13, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
